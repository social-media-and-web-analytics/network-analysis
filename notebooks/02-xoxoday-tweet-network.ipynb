{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df29ca7c",
   "metadata": {},
   "source": [
    "# Xoxoday Tweet Network\n",
    "Let's now move onto some real data used in the Xoxoday case study.\n",
    "\n",
    "Let's import `pandas` and `networkx` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628db6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4736f67",
   "metadata": {},
   "source": [
    "Let's import the \"Tweets Data\" sheet (in CVS format) from the Xoxoday data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b9594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./xoxoday_tweets_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16a649",
   "metadata": {},
   "source": [
    "Let's create a small (de-duplicated) DataFrame of tweets containing just the Tweets ID, text, the date-time it was created, and the ID of the tweet replied to if the tweet was a reply (otherwise `NaN`). This is all we really need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df[['Imported ID','Tweet','Tweet Date (UTC)','In-Reply Tweet ID']]\n",
    "df_tweets = df_tweets.drop_duplicates(subset=['Imported ID'])\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f80e0",
   "metadata": {},
   "source": [
    "## Construct Tweet Network\n",
    "Let's now construct a \"Tweet Network\" using the data provided. This is a graph where the nodes represent tweets and the edges represent relationships between the tweets. The `Imported ID` column in the dataset contains the set of Tweets ID's, some of which we will use to represent tweets as nodes. With regards to edges, we will create an edge directed from one tweet to another if the first tweet was a reply to the other, indicated by `In-Reply Tweet ID`.\n",
    "\n",
    "Thus, we will create an `edgelist` for the Tweet Network using the following method:\n",
    "1. Initiate the edge list using the `Imported ID` and `In-Reply Tweet ID` columns\n",
    "2. Drop edges that were not replies (i.e., `NaN` in `In-Reply Tweet ID` column)\n",
    "3. Drop duplicates (as tweets are duplicated in the dataset) and ensure the node ID's are integer valued\n",
    "4. Create edge weights that are all equal to $1$ (as the reply relationship is binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ddbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_edgelist = df_tweets[['Imported ID','In-Reply Tweet ID']]\n",
    "tweets_edgelist = tweets_edgelist.dropna().drop_duplicates().astype(int)\n",
    "tweets_edgelist['Weight'] = 1\n",
    "tweets_edgelist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22e866",
   "metadata": {},
   "source": [
    "Next we create the network / graph using `from_pandas_edgelist` and visualise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14142d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(\n",
    "    tweets_edgelist, \n",
    "    source='Imported ID', \n",
    "    target='In-Reply Tweet ID', \n",
    "    edge_attr='Weight',\n",
    "    create_using=nx.DiGraph(),\n",
    ")\n",
    "\n",
    "nx.draw_spring(G, node_size=5, arrowsize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe5fda6",
   "metadata": {},
   "source": [
    "**Question:** What do you see? Can you explain it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec0d45",
   "metadata": {},
   "source": [
    "## Tweet Network Analysis\n",
    "Let's now perform some quantitative analysis of the tweet network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, K = G.order(), G.size()\n",
    "avg_deg = float(K) / N\n",
    "print(f'Nodes: {N}')\n",
    "print(f'Edges: {K}')\n",
    "print(f'Average degree: {avg_deg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a0e07",
   "metadata": {},
   "source": [
    "**Question:** How can we interpret the average degree in terms of how many tweets reply to other tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa85389",
   "metadata": {},
   "source": [
    "Let's now compute the in-degree of each node (i.e. the number of replies of each tweet) and print the top 5 tweets with highest in-degree (i.e., most replies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degrees_sorted = sorted(G.in_degree(), key=lambda tup: tup[1], reverse=True)\n",
    "for tweet_ID, in_degree in in_degrees_sorted[:5]:\n",
    "    tweet_text = df_tweets.query(f'`Imported ID` == {tweet_ID}').Tweet.values\n",
    "    print(f'Tweet ID: {tweet_ID}')\n",
    "    print(f'Importance: {in_degree}')\n",
    "    print(f'Tweet text: {tweet_text}')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbdef03",
   "metadata": {},
   "source": [
    "## Tweet Content Analysis\n",
    "Looks like a number of the tweets with high in-degrees relate to a \"contest\". Let's investigate if tweets relating to contests really do have higher in-degrees (number of replies). To do this, we will:\n",
    "1. Create a new DataFrame for the labelled tweets (using the `df_tweets` DataFrame from before)\n",
    "2. Label the tweets as contest or not based on whether the text contains the \"contest\" string (ignoring case)\n",
    "3. Create an `In-degree` column in the DataFrame to store the in-degree values for each tweet\n",
    "4. Calculate the mean `In-degree` value (number of replies) for contest and not contest labelled tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa99955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_labeled = df_tweets.copy()\n",
    "df_tweets_labeled['Contest'] = df_tweets_labeled['Tweet'].str.contains('contest',case=False)\n",
    "\n",
    "# Create in-degree column\n",
    "in_degrees_dict = {node:in_degree for node,in_degree in in_degrees_sorted}\n",
    "in_degrees_func = lambda ID: in_degrees_dict[ID] if ID in in_degrees_dict else 0\n",
    "df_tweets_labeled['In-degree'] = df_tweets_labeled['Imported ID'].apply(in_degrees_func)\n",
    "\n",
    "# Calculate mean In-degree value for contest and not contest labelled tweets\n",
    "df_tweets_labeled.groupby('Contest').agg({'In-degree':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d7fcf9",
   "metadata": {},
   "source": [
    "## Exercise 01 - Analysis in action\n",
    "Explain if/how Xoxoday could use the above analysis and identify potential limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f57c5c",
   "metadata": {},
   "source": [
    "## Exercise 02 - Betweeness Centrality\n",
    "In the previous tweet analysis, we use the in-degree of tweets to order tweets in terms of potential influence, but the in-degree of the tweets (in this network) is simply the number of replies to the tweet. This could be collected from the `public_metrics` data using Twitter API. Let's try a different metric which is not included in `public_metrics`.\n",
    "\n",
    "The code below calculates the [betweeness centrality](https://en.wikipedia.org/wiki/Betweenness_centrality) of the nodes in the graph. Sort the degree centralities and print the 5 most \"important\" tweets w.r.t. betweeness centrality. Are you able to use the definition of betweeness centrality to explain why you are seeing the results you are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef5c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centralities = nx.betweenness_centrality(G).items()\n",
    "\n",
    "# (SOLUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940c43b",
   "metadata": {},
   "source": [
    "## (Optional) Exercise 03 - Content relevance\n",
    "Find some other words (in addition to \"contest\" found in the tweets) which are strongly associated with an increase activity (e.g. number of replies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28748fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (SOLUTION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
